# Data Wrangling
Before the data sets could be combined, substantial data wrangling was necessary. The details of these processes; obtaining, checking, mapping identifiers, excluding irrelevant data, etc, are described in this section.
<!--TODO: Signpost to appendix if appropriate-->

### Overview
The steps required to obtain consistently formatted and labelled data can be described as follows:
1. Obtaining the raw expression per gene for healthy human tissues
    A. Obtaining data
    B. (Where required) Mapping from transcript to gene
    C. (Where required) Filtering out disease samples
    D. (Where required) Filtering out non-human samples
2. Mapping from sample name to UBERON tissue
3. Aggregating metadata

<!--TODO: Check reference `combining-data-pipeline` works -->

```{python combining-data-pipeline, fig.align='center', fig.cap='Funnel plot showing the data cleaning pipeline for FANTOM transcripts/genes (left) and samples (right), along with the number which remained after each stage of data cleaning.' }
# Code here for creating data wrangling pipeline image. Steps should be labelled matching 1A, 1B, etc.
```

{numref}`combining-data-pipeline` shows an overview of the data wrangling pipeline. Additional steps 1A, 1B, and 1C were only necessary for the FANTOM dataset.

**1A\. Obtaining raw expression per gene for healthy human tissues**
<!--TODO: Check how raw the data was and if it's sensible to refer to it that way)-->

Raw data was obtained, where possible via the *ExpressionAtlas* R package[107], which gives gene expression counts identified by ENSG IDs, metadata (containing pipeline, filtering, mapping and quantification information), and details of experimental design (containing for example organism part name, individual demographics, and replicate information, depending on the experiment). 

For the HPA, GTeX and HDBR experiments, count data were available through the *ExpressionAtlas* R package[107], while this was not the case for the FANTOM dataset. 

For the FANTOM experiment counts for transcript expression were downloaded directly [from the FANTOM website](http://fantom.gsc.riken.jp/5/datafiles/reprocessed/hg38_latest/extra/CAGE_peaks_expression/hg38_fair+new_CAGE_peaks_phase1and2_counts_ann.osc.txt.gz).  
The downloaded FANTOM5 file has already undergone some quality control by FANTOM, it is limited to peaks which meet a “robust” threshold (>10 read counts and 1TPM for at least one sample). 

**1B\. Mapping from transcript to gene** 

This step was only required for the FANTOM dataset.
<!--TODO: sentence about why FANTOM is per transcript - CAGE)-->
<!--TODO: cite biomart-->

FANTOM provides mappings to gene IDs based on proximity of genes to peaks according to Ensembl. Gene expression was then calculated by summing over transcripts mapped to genes. The transcripts were already mapped to HGNC gene identifiers in the downloaded FANTOM file and [Ensembl’s Biomart](https://www.ensembl.org/biomart) was used to obtain a mapping from HGNC gene identifiers to ENSG gene identifiers, in order to match the gene expression atlas format. 

Any transcripts which mapped to multiple genes were discarded, as were any HGNC ids which did not map to ENSG ids.

**1C\. Filtering out disease samples**

The HDBR and HPA experiments contained only healthy samples. 

**GTEx**
Although GTEx contained clinical data, no disease-related phenotypes were removed from the data set, since the `disease` column contains only values of “normal” and the only clinical variables (as described in the `clinical_variables` column) in the dataset were sun exposure or lack thereof for skin tissues. I judged these to be within the normal range of environments that we would expect skin to be subjected to.

**FANTOM**
The FANTOM sample ontology was used to remove samples which are models for diseases. Samples which are disease models are identified using the `is_model_for` relationship and these relationships are propagated to the children terms based on the `is_a` relationship. For example, `FF:11558-120D1` (Fibroblast - skin spinal muscular atrophy, donor2) would be removed from the set of samples, since:
`FF:11558-120D1` (Fibroblast - skin spinal muscular atrophy, donor2) `is_a FF:0000251` (human fibroblast - skin spinal muscular atrophy sample) `is_model_for DOID:12377` (spinal muscular atrophy).


**1D\. Filtering out non-human samples**

The GTEx, HDBR, and HPA experiments contained only human samples. 

**FANTOM**
The FANTOM5 data set also contains non-human (mouse) samples. The FANTOM sample ontology (which was downloaded [from here](http://fantom.gsc.riken.jp/5/datafiles/latest/extra/Ontology/ff-phase2-170801.obo.txt)) was used to look-up which FANTOM samples are human samples, i.e. have an `is_a` relationship to the term `FF:0000210` (human sample) directly or indirectly. 

**2\. Mapping to UBERON**
<!--TODO: tidy this section-->

Mapping from samples to Uberon tissue required the development of a small Python package `uberon_py`. To create input to this package, informal tissue names (e.g. blood, kidney) were taken from the experimental design files (or the human sample information file for FANTOM) to create a map of samples to informal tissue names. For FANTOM, the FANTOM ontology could also be used to create a more fine-grained mapping of samples to tissues based on FANTOM sample identifiers and/or cell type (CL) identifiers.

**FANTOM**
FANTOM also contains time courses of cell differentiation (cells changing from one type to another) as well measures of perturbed cells. Since these samples do not have a well-defined locality in the body given by cell or tissue type, they were not used in the combined dataset. Such samples were filtered out using the human sample information spreadsheet.

**3/. Aggregating Metadata**
<!-- TODO: details here-->
To create consistent metadata for the samples (e.g. age, developmental stage, replicate status, etc), information was extracted from multiple sources (including GxA and additional data from each experiment), and sometimes manually curated or corrected. 

```{python combining-funnel-plot, fig.align='center', fig.cap='Funnel plot showing the data cleaning pipeline for FANTOM transcripts/genes (left) and samples (right), along with the number which remained after each stage of data cleaning.' }
# Code here for creating data wrangling pipeline image. Steps should be labelled matching 1A, 1B, etc.
```

{numref}`combining-funnel-plot` shows a funnel plot, showing how the FANTOM5 data was processed to select the final genes and samples present in the combined dataset. 

---
**Page References**

```{bibliography} /_bibliography/references.bib
:filter: docname in docnames
:style: unsrt
```
